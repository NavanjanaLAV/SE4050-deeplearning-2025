{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NavanjanaLAV/SE4050-deeplearning-2025/blob/IT22609908-bert-distil/bert_distil.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "DTzQ_MS37dlu"
      },
      "id": "DTzQ_MS37dlu",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch transformers datasets pandas scikit-learn"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Ot9Qkss-HDVy",
        "outputId": "6eb72a3e-6119-45d2-8877-5d8add2177cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Ot9Qkss-HDVy",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "122daff3",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "122daff3"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "url = \"https://raw.githubusercontent.com/NavanjanaLAV/SE4050-deeplearning-2025/main/Dataset/fake_or_real_news_cleaned.csv\"\n",
        "df = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check first few rows\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "tYTDvwQvLpPi",
        "outputId": "1cd80cd8-3bbf-4ca0-83cc-011234cf1e99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tYTDvwQvLpPi",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title  label\n",
            "0  ben stein calls th circuit court committed cou...      0\n",
            "1  trump drops steve bannon national security cou...      1\n",
            "2  puerto rico expects us lift jones act shipping...      1\n",
            "3  oops trump accidentally confirmed leaked israe...      0\n",
            "4     donald trump heads scotland reopen golf resort      1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 -  Split into Train and Test"
      ],
      "metadata": {
        "id": "FCVXjGb_PU__"
      },
      "id": "FCVXjGb_PU__"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "o0onlPzLG_Wi"
      },
      "id": "o0onlPzLG_Wi",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic Data Checks"
      ],
      "metadata": {
        "id": "0jJ7QZmwNZLY"
      },
      "id": "0jJ7QZmwNZLY"
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "pdFzEWOWL7ma",
        "outputId": "9012a843-25ec-4520-b9a3-842f28cd1967",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "pdFzEWOWL7ma",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values:\n",
            "title    0\n",
            "label    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows where 'title' or 'label' is missing\n",
        "df = df.dropna(subset=['title', 'label'])"
      ],
      "metadata": {
        "id": "rvIhbgHZNgEo"
      },
      "id": "rvIhbgHZNgEo",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure label is int (0/1)\n",
        "df['label'] = df['label'].astype(int)"
      ],
      "metadata": {
        "id": "gYDH_alyNmIv"
      },
      "id": "gYDH_alyNmIv",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check class distribution\n",
        "print(\"\\nLabel distribution:\")\n",
        "print(df['label'].value_counts())"
      ],
      "metadata": {
        "id": "rv8HbBUiNqJk",
        "outputId": "d0807c87-f573-473e-bf41-e8e828d1136f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "rv8HbBUiNqJk",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label distribution:\n",
            "label\n",
            "0    23481\n",
            "1    21417\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split into Train & Validation Sets"
      ],
      "metadata": {
        "id": "nqRrDdWbNzP5"
      },
      "id": "nqRrDdWbNzP5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract texts and labels\n",
        "texts = df['title'].tolist()      # list of headlines\n",
        "labels = df['label'].tolist()     # list of 0s and 1s"
      ],
      "metadata": {
        "id": "ifjo8L6pOO2q"
      },
      "id": "ifjo8L6pOO2q",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split: 80% train, 20% validation\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    texts,\n",
        "    labels,\n",
        "    test_size=0.2,           # 20% for validation\n",
        "    stratify=labels,         # keep same ratio of 0/1 in both sets\n",
        "    random_state=42          # for reproducibility\n",
        ")"
      ],
      "metadata": {
        "id": "WsQC75fVOUIh"
      },
      "id": "WsQC75fVOUIh",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print sizes\n",
        "print(f\"Training samples: {len(train_texts)}\")\n",
        "print(f\"Validation samples: {len(val_texts)}\")"
      ],
      "metadata": {
        "id": "-C76EXLsOX_R",
        "outputId": "2e5496b1-5988-4539-e0f2-06cf0af09240",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-C76EXLsOX_R",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 35918\n",
            "Validation samples: 8980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Splits to Disk"
      ],
      "metadata": {
        "id": "Ciyi3hZ6Oj1h"
      },
      "id": "Ciyi3hZ6Oj1h"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrames for each split\n",
        "train_df = pd.DataFrame({'title': train_texts, 'label': train_labels})\n",
        "val_df = pd.DataFrame({'title': val_texts, 'label': val_labels})"
      ],
      "metadata": {
        "id": "MgwF_H_ZOk7S"
      },
      "id": "MgwF_H_ZOk7S",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to CSV\n",
        "train_df.to_csv('train.csv', index=False)\n",
        "val_df.to_csv('val.csv', index=False)"
      ],
      "metadata": {
        "id": "1saeSiruOp7Q"
      },
      "id": "1saeSiruOp7Q",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify splits are stratified (balanced)\n",
        "print(\"Train label distribution:\")\n",
        "print(pd.Series(train_labels).value_counts())\n",
        "\n",
        "print(\"\\nValidation label distribution:\")\n",
        "print(pd.Series(val_labels).value_counts())"
      ],
      "metadata": {
        "id": "bYge2mkwO_gh",
        "outputId": "fd2b3f75-a333-4e45-d492-817e1100391f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bYge2mkwO_gh",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train label distribution:\n",
            "0    18785\n",
            "1    17133\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Validation label distribution:\n",
            "0    4696\n",
            "1    4284\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 - Tokenize Text with BERT Tokenizer"
      ],
      "metadata": {
        "id": "NlrQiFwFPj7Z"
      },
      "id": "NlrQiFwFPj7Z"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}