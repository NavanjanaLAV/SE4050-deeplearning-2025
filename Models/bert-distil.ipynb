{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NavanjanaLAV/SE4050-deeplearning-2025/blob/it22609908-distil-bert/Models/bert-distil.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "WVHCKAfMqDyb"
      },
      "id": "WVHCKAfMqDyb",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPRsgTVhqm3o",
        "outputId": "eb76fe03-0e6d-41dc-d42b-ad43abe5e5e4"
      },
      "id": "EPRsgTVhqm3o",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.2)\n",
            "Collecting transformers\n",
            "  Using cached transformers-4.57.0-py3-none-any.whl.metadata (41 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Using cached transformers-4.57.0-py3-none-any.whl (12.0 MB)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.56.2\n",
            "    Uninstalling transformers-4.56.2:\n",
            "      Successfully uninstalled transformers-4.56.2\n",
            "Successfully installed transformers-4.57.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "url = \"https://raw.githubusercontent.com/NavanjanaLAV/SE4050-deeplearning-2025/main/Dataset/fake_or_real_news_cleaned.csv\"\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "6jhJ7nGjqqYh"
      },
      "id": "6jhJ7nGjqqYh",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check first few rows\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ky9gmskyqsw2",
        "outputId": "6ecb5f0b-6e82-4696-fe0c-de4d50f8ffee"
      },
      "id": "Ky9gmskyqsw2",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title  label\n",
            "0  ben stein calls th circuit court committed cou...      0\n",
            "1  trump drops steve bannon national security cou...      1\n",
            "2  puerto rico expects us lift jones act shipping...      1\n",
            "3  oops trump accidentally confirmed leaked israe...      0\n",
            "4     donald trump heads scotland reopen golf resort      1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 -  Split into Train and Test"
      ],
      "metadata": {
        "id": "E5qOeSuTrbax"
      },
      "id": "E5qOeSuTrbax"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "xnn-kifurEMh"
      },
      "id": "xnn-kifurEMh",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic Data Checks"
      ],
      "metadata": {
        "id": "kMnAv4CDrh2r"
      },
      "id": "kMnAv4CDrh2r"
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "YHghlL8MrjDy",
        "outputId": "7a07c83b-f5a2-4126-b6cf-0c023315f9f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "YHghlL8MrjDy",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values:\n",
            "title    0\n",
            "label    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows where 'title' or 'label' is missing\n",
        "df = df.dropna(subset=['title', 'label'])"
      ],
      "metadata": {
        "id": "rWlWaR9irnA8"
      },
      "id": "rWlWaR9irnA8",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure label is int (0/1)\n",
        "df['label'] = df['label'].astype(int)"
      ],
      "metadata": {
        "id": "C-L6C0f5rp4R"
      },
      "id": "C-L6C0f5rp4R",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check class distribution\n",
        "print(\"\\nLabel distribution:\")\n",
        "print(df['label'].value_counts())"
      ],
      "metadata": {
        "id": "PT1_PSELrs6C",
        "outputId": "468376c4-5ec7-4afe-8872-580f0f3ca5e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "PT1_PSELrs6C",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label distribution:\n",
            "label\n",
            "0    23481\n",
            "1    21417\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split into Train & Validation Sets"
      ],
      "metadata": {
        "id": "0o5L4DHOrw6u"
      },
      "id": "0o5L4DHOrw6u"
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract texts and labels\n",
        "texts = df['title'].tolist()      # list of headlines\n",
        "labels = df['label'].tolist()     # list of 0s and 1s"
      ],
      "metadata": {
        "id": "YLYxQ3NNrwi-"
      },
      "id": "YLYxQ3NNrwi-",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split: 80% train, 20% validation\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    texts,\n",
        "    labels,\n",
        "    test_size=0.2,           # 20% for validation\n",
        "    stratify=labels,         # keep same ratio of 0/1 in both sets\n",
        "    random_state=42          # for reproducibility\n",
        ")"
      ],
      "metadata": {
        "id": "yZCSCQrXr1iA"
      },
      "id": "yZCSCQrXr1iA",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print sizes\n",
        "print(f\"Training samples: {len(train_texts)}\")\n",
        "print(f\"Validation samples: {len(val_texts)}\")"
      ],
      "metadata": {
        "id": "F6VvdiK1r3cz",
        "outputId": "1775e66d-c48b-4a7e-96d3-dd5cbabf1d8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "F6VvdiK1r3cz",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 35918\n",
            "Validation samples: 8980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Splits to Disk"
      ],
      "metadata": {
        "id": "pkjobRIIr-Gd"
      },
      "id": "pkjobRIIr-Gd"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrames for each split\n",
        "train_df = pd.DataFrame({'title': train_texts, 'label': train_labels})\n",
        "val_df = pd.DataFrame({'title': val_texts, 'label': val_labels})"
      ],
      "metadata": {
        "id": "BTk4yhnHr72h"
      },
      "id": "BTk4yhnHr72h",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to CSV\n",
        "train_df.to_csv('train.csv', index=False)\n",
        "val_df.to_csv('val.csv', index=False)"
      ],
      "metadata": {
        "id": "BAXmZWP2sCiA"
      },
      "id": "BAXmZWP2sCiA",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify splits are stratified (balanced)\n",
        "print(\"Train label distribution:\")\n",
        "print(pd.Series(train_labels).value_counts())\n",
        "\n",
        "print(\"\\nValidation label distribution:\")\n",
        "print(pd.Series(val_labels).value_counts())"
      ],
      "metadata": {
        "id": "NCgBButnsFE5",
        "outputId": "2a08ac5b-710b-49fd-db2a-d744d08b5244",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NCgBButnsFE5",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train label distribution:\n",
            "0    18785\n",
            "1    17133\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Validation label distribution:\n",
            "0    4696\n",
            "1    4284\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 - Load DistilBERT Tokenizer\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bS6HeB0ptBLZ"
      },
      "id": "bS6HeB0ptBLZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the fast tokenizer for DistilBERT from Hugging Face Transformers\n",
        "from transformers import DistilBertTokenizerFast"
      ],
      "metadata": {
        "id": "spgBywPwtDzB"
      },
      "id": "spgBywPwtDzB",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸš€ Load pre-trained tokenizer\n",
        "# We use 'distilbert-base-uncased' because:\n",
        "#   - Our headlines are in English and case doesn't matter much â†’ \"uncased\" is fine\n",
        "#   - \"base\" = standard size (not tiny or large)\n",
        "#   - \"distilbert\" = lightweight BERT, great for headlines & fast training\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
      ],
      "metadata": {
        "id": "eMhSyTXju4Yl",
        "outputId": "78e09a98-d649-47d7-e4b6-3edb0a7407b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "eMhSyTXju4Yl",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the tokenizer on a sample headline to see how it works\n",
        "sample_headline = \"Trump drops Steve Bannon from security council\"\n",
        "encoded = tokenizer(sample_headline, truncation=True, padding=True, max_length=128)\n",
        "\n",
        "print(\"Tokenizer loaded successfully!\")\n",
        "print(f\"Sample input: '{sample_headline}'\")\n",
        "print(f\"Tokenized output keys: {list(encoded.keys())}\")\n",
        "print(f\"Input IDs (first 10): {encoded['input_ids'][:10]}\")\n",
        "print(f\"Attention Mask (first 10): {encoded['attention_mask'][:10]}\")"
      ],
      "metadata": {
        "id": "_PkPjquHvGkg",
        "outputId": "c7b519f8-11b2-48f0-8964-1f78c3af524d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_PkPjquHvGkg",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer loaded successfully!\n",
            "Sample input: 'Trump drops Steve Bannon from security council'\n",
            "Tokenized output keys: ['input_ids', 'attention_mask']\n",
            "Input IDs (first 10): [101, 8398, 9010, 3889, 7221, 8540, 2013, 3036, 2473, 102]\n",
            "Attention Mask (first 10): [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize full Train & Val Sets"
      ],
      "metadata": {
        "id": "r6axlT14wXQB"
      },
      "id": "r6axlT14wXQB"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "0Pv-18mowaxR"
      },
      "id": "0Pv-18mowaxR",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define max_length â€” 128 is safe for headlines\n",
        "MAX_LEN = 128\n",
        "\n",
        "# Tokenize train set\n",
        "train_encodings = tokenizer(\n",
        "    train_texts,\n",
        "    truncation=True,\n",
        "    padding=True,        # or 'max_length' â€” both work\n",
        "    max_length=MAX_LEN,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "# Tokenize validation set\n",
        "val_encodings = tokenizer(\n",
        "    val_texts,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=MAX_LEN,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "print(\"Tokenization complete!\")\n",
        "print(\"Train input shape:\", train_encodings['input_ids'].shape)\n",
        "print(\"Val input shape:\", val_encodings['input_ids'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLRJAVMOxBlJ",
        "outputId": "9c3713f9-937b-47c5-cd79-4ad0dbe43592"
      },
      "id": "NLRJAVMOxBlJ",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization complete!\n",
            "Train input shape: torch.Size([35918, 51])\n",
            "Val input shape: torch.Size([8980, 39])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create PyTorch Datasets for Trainer"
      ],
      "metadata": {
        "id": "Nf6FAKbUzOKA"
      },
      "id": "Nf6FAKbUzOKA"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "nWt8xucwywmd"
      },
      "id": "nWt8xucwywmd",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Custom Dataset for fake news classification.\n",
        " # Returns: {'input_ids', 'attention_mask', 'labels'} for each sample.\n",
        "class FakeNewsDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Return a dictionary with all tensor inputs + label\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "pn13tQjmzXTg"
      },
      "id": "pn13tQjmzXTg",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create final datasets for training and validation\n",
        "train_dataset = FakeNewsDataset(train_encodings, train_labels)\n",
        "val_dataset = FakeNewsDataset(val_encodings, val_labels)"
      ],
      "metadata": {
        "id": "2kh7gO3Yz16A"
      },
      "id": "2kh7gO3Yz16A",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training dataset ready: {len(train_dataset)} samples\")\n",
        "print(f\"Validation dataset ready: {len(val_dataset)} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwX4kTgaz5_y",
        "outputId": "6a997e8c-2a7d-4592-97d5-f24943bb2b99"
      },
      "id": "zwX4kTgaz5_y",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset ready: 35918 samples\n",
            "Validation dataset ready: 8980 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load DistilBERT Model for Binary Classification"
      ],
      "metadata": {
        "id": "swjxlTVC0V8p"
      },
      "id": "swjxlTVC0V8p"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertForSequenceClassification"
      ],
      "metadata": {
        "id": "2lOVE4Q_0YL4"
      },
      "id": "2lOVE4Q_0YL4",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained DistilBERT model + add classification head on top\n",
        "# 'distilbert-base-uncased' = lightweight, fast, perfect for headlines\n",
        "# num_labels=2 â†’ fake (0) vs real (1)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    'distilbert-base-uncased',\n",
        "    num_labels=2,\n",
        "    problem_type=\"single_label_classification\"  # explicitly tell it we're doing single-label (not multi)\n",
        ")"
      ],
      "metadata": {
        "id": "-LMdhTxV0uNh",
        "outputId": "d0893b03-62d7-44fb-8ac5-5dcb6a33ee1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-LMdhTxV0uNh",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Check model architecture summary (first layer)\n",
        "print(\"Model loaded successfully!\")\n",
        "print(f\"Model type: {type(model).__name__}\")\n",
        "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")"
      ],
      "metadata": {
        "id": "twqtNa9j1D4x",
        "outputId": "cb327395-b74d-4368-8b85-1e1c9e9ce7e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "twqtNa9j1D4x",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n",
            "Model type: DistilBertForSequenceClassification\n",
            "Number of parameters: 66,955,010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model to GPU if available (much faster training!)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(f\"Model is running on device: {device}\")"
      ],
      "metadata": {
        "id": "xk63tit81YjM",
        "outputId": "0c26f28f-e6ac-48dd-bd09-98d9612ef765",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xk63tit81YjM",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is running on device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Peek at classifier head (last layer) â€” should output 2 logits\n",
        "classifier_head = model.classifier\n",
        "print(f\"Classifier head: {classifier_head}\")"
      ],
      "metadata": {
        "id": "vSMLUXZv1hgQ",
        "outputId": "dba46445-756d-4fe2-f3f9-9493239672c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vSMLUXZv1hgQ",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier head: Linear(in_features=768, out_features=2, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Training"
      ],
      "metadata": {
        "id": "BHbIc94PPXyg"
      },
      "id": "BHbIc94PPXyg"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from transformers import TrainingArguments, Trainer"
      ],
      "metadata": {
        "id": "r2icHfELPXP2"
      },
      "id": "r2icHfELPXP2",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING ARGS\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./fake-news-results',\n",
        "    # evaluation_strategy='epoch',\n",
        "    # save_strategy='epoch',\n",
        "    # logging_steps=100,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=100,\n",
        "    report_to='none',\n",
        "    seed=42,\n",
        "    fp16=torch.cuda.is_available(),\n",
        ")"
      ],
      "metadata": {
        "id": "mvDPmzX0PgzS"
      },
      "id": "mvDPmzX0PgzS",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# METRIC FUNCTION\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred  # Modelâ€™s raw scores + true answers\n",
        "    predictions = np.argmax(logits, axis=-1)  # Turn scores into 0 (fake) or 1 (real)\n",
        "    return {'accuracy': accuracy_score(labels, predictions)} # % correct\n",
        "\n",
        "# Example :- {'eval_loss': 0.243, 'eval_accuracy': 0.9263}"
      ],
      "metadata": {
        "id": "cWSECH1tPo_y"
      },
      "id": "cWSECH1tPo_y",
      "execution_count": 33,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}